## Book
- [深層学習による画像認識の基礎](https://www.ohmsha.co.jp/book/9784274231841/)
- [GitHub](https://github.com/sg-nm/image-recognition)
- Purchase Date: YYMMDD (kinoppy)

<img src="https://www.ohmsha.co.jp/Portals/0/book/large/978-4-274-23184-1.jpg" height="150px">

## CheckList
- [x] **第1章　画像認識の概要**
  - [x] 1.1　画像認識とは
  - [x] 1.2　基本的な画像分類の方法
  - [x] 1.3　画像認識の歴史の概略
  - [x] 1.4　機械学習とは

- [ ] **第2章　深層学習の基礎**
  - [ ] 2.1　深層学習の基本概念
  - [ ] 2.2　多層パーセプトロン
  - [ ] 2.3　損失関数
  - [ ] 2.4　勾配降下法
  - [ ] 2.5　誤差逆伝播法
  - [ ] 2.6　画像分類の実装
  - [ ] 2.7　深層学習の成功に欠かせない技術
  - [ ] 2.8　本章のまとめ

- [ ] **第3章　畳込みニューラルネットワーク**
  - [ ] 3.1　畳込みニューラルネットワークの概要
  - [ ] 3.2　畳込み層
  - [ ] 3.3　プーリング層
  - [ ] 3.4　出力層
  - [ ] 3.5　様々な畳込み層
  - [ ] 3.6　代表的なCNN
  - [ ] 3.7　本章のまとめ

- [ ] **第4章　Vision Transformer**
  - [ ] 4.1　Vision Transformerの登場
  - [ ] 4.2　ViTの概要
  - [ ] 4.3　ViTの効果的な学習方法
  - [ ] 4.4　ViTの軽量化
  - [ ] 4.5　位置情報の表現方法
  - [ ] 4.6　ViTの解析
  - [ ] 4.7　ViTのメタアーキテクチャ
  - [ ] 4.8　本章のまとめ

- [ ] **第5章　物体検出**
  - [ ] 5.1　物体検出とは
  - [ ] 5.2　CNNによる物体検出
  - [ ] 5.3　ViTによる物体検出
  - [ ] 5.4　物体検出器の性能評価
  - [ ] 5.5　本章のまとめ

- [ ] **第6章　領域分割**
  - [ ] 6.1　領域分割とは
  - [ ] 6.2　意味的領域分割
  - [ ] 6.3　インスタンス領域分割
  - [ ] 6.4　総括的領域分割
  - [ ] 6.5　Segment Anything Model
  - [ ] 6.6　本章のまとめ

- [ ] **第7章　自己教師あり学習**
  - [ ] 7.1　教師あり学習の課題
  - [ ] 7.2　自己教師あり学習による表現学習
  - [ ] 7.3　対比学習（対照学習）に基づく表現学習
  - [ ] 7.4　負例が不要な表現学習
  - [ ] 7.5　自己教師あり学習手法の性能評価
  - [ ] 7.6　本章のまとめ

- [ ] **第8章　画像と自然言語**
  - [ ] 8.1　画像と自然言語とは
  - [ ] 8.2　Transformer台頭前のV&Lモデル
  - [ ] 8.3　Transformer台頭後のV&Lモデル
  - [ ] 8.4　大規模言語モデルを利用したV&L
  - [ ] 8.5　自然言語を利用した画像認識
  - [ ] 8.6　本章のまとめ
